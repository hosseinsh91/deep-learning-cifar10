{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bca770c-1f4f-495c-91cb-89eaaf47aa8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-19 18:56:16.421401: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras_tuner\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPooling2D\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from genetic_selection import GeneticSelectionCV\n",
    "from scikeras.wrappers import KerasClassifier, KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d33d4ed-1204-4671-a3c2-b41402840839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14b3ed4-85dd-4775-8459-e6cc009463bf",
   "metadata": {},
   "source": [
    "## Shapes of input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "15ad2906-226a-4cfe-b4ca-ce7ab9ab3943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "20463b39-3c4f-4305-9838-1626b3259371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The dimensions of the input images\n",
    "x_test.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "4bd6f73d-7dca-4f87-8c5c-8ceebb36b4cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 1)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The shape of output\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f153057a-d18a-442f-8654-a97b6008a999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f81ad038a30>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[2,], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7371f7c1-d924-4b14-95bf-14fff404af2f",
   "metadata": {},
   "source": [
    "## Concatenating the data from the training and testing sets and splitting training and testing sets with a test size of 15%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "05f8d51c-ae1d-4e17-95ee-af5bfbb882f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_features = np.concatenate((x_train, x_test))\n",
    "combined_targets = np.concatenate((y_train, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c4952c27-eb8e-4cdf-9654-9567235d2d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train0, X_test0, y_train0, y_test0 = train_test_split(combined_features,combined_targets ,test_size = 0.15 ,random_state = 42 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fa840c-9c0f-4b9f-aaa7-d87d083ac23f",
   "metadata": {},
   "source": [
    "## Normalization train sets by dividing the values by 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "ab1327b3-b695-4e14-bb3d-f9588e44fed8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[105, 115, 165],\n",
       "         [ 87,  96, 153],\n",
       "         [114, 124, 178],\n",
       "         ...,\n",
       "         [ 41,  41,  70],\n",
       "         [ 31,  31,  59],\n",
       "         [ 33,  33,  61]],\n",
       "\n",
       "        [[115, 125, 174],\n",
       "         [116, 125, 181],\n",
       "         [ 94, 104, 159],\n",
       "         ...,\n",
       "         [ 47,  45,  78],\n",
       "         [ 32,  31,  58],\n",
       "         [ 34,  34,  58]],\n",
       "\n",
       "        [[113, 124, 172],\n",
       "         [131, 140, 198],\n",
       "         [102, 111, 170],\n",
       "         ...,\n",
       "         [ 47,  45,  83],\n",
       "         [ 39,  39,  69],\n",
       "         [ 41,  41,  69]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 94,  94, 133],\n",
       "         [ 61,  61,  93],\n",
       "         [ 62,  58,  90],\n",
       "         ...,\n",
       "         [123, 130, 209],\n",
       "         [118, 126, 204],\n",
       "         [113, 122, 200]],\n",
       "\n",
       "        [[ 89,  94, 138],\n",
       "         [ 64,  70, 108],\n",
       "         [ 70,  70, 105],\n",
       "         ...,\n",
       "         [119, 129, 209],\n",
       "         [117, 126, 205],\n",
       "         [115, 123, 203]],\n",
       "\n",
       "        [[ 85,  93, 142],\n",
       "         [ 65,  71, 110],\n",
       "         [ 81,  79, 113],\n",
       "         ...,\n",
       "         [119, 129, 209],\n",
       "         [117, 126, 207],\n",
       "         [115, 123, 204]]],\n",
       "\n",
       "\n",
       "       [[[174, 162, 150],\n",
       "         [195, 183, 170],\n",
       "         [216, 204, 190],\n",
       "         ...,\n",
       "         [163, 156, 144],\n",
       "         [132, 130, 125],\n",
       "         [104, 104, 114]],\n",
       "\n",
       "        [[198, 186, 170],\n",
       "         [206, 194, 181],\n",
       "         [212, 200, 189],\n",
       "         ...,\n",
       "         [119, 113, 109],\n",
       "         [ 72,  72,  76],\n",
       "         [ 68,  71,  88]],\n",
       "\n",
       "        [[159, 146, 137],\n",
       "         [168, 156, 143],\n",
       "         [193, 181, 165],\n",
       "         ...,\n",
       "         [ 58,  53,  59],\n",
       "         [ 48,  49,  63],\n",
       "         [ 61,  66,  89]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[130, 126, 125],\n",
       "         [126, 122, 119],\n",
       "         [125, 118, 115],\n",
       "         ...,\n",
       "         [109, 130, 150],\n",
       "         [ 82, 108, 135],\n",
       "         [ 82, 111, 140]],\n",
       "\n",
       "        [[117, 118, 117],\n",
       "         [117, 118, 118],\n",
       "         [114, 115, 117],\n",
       "         ...,\n",
       "         [ 80, 105, 129],\n",
       "         [ 77, 104, 133],\n",
       "         [ 83, 110, 139]],\n",
       "\n",
       "        [[120, 128, 126],\n",
       "         [116, 125, 125],\n",
       "         [103, 114, 116],\n",
       "         ...,\n",
       "         [110, 136, 162],\n",
       "         [100, 127, 157],\n",
       "         [ 83, 111, 141]]],\n",
       "\n",
       "\n",
       "       [[[241, 215, 158],\n",
       "         [239, 216, 162],\n",
       "         [243, 220, 168],\n",
       "         ...,\n",
       "         [211, 193, 136],\n",
       "         [202, 185, 126],\n",
       "         [198, 184, 131]],\n",
       "\n",
       "        [[241, 214, 157],\n",
       "         [240, 217, 160],\n",
       "         [242, 220, 162],\n",
       "         ...,\n",
       "         [216, 196, 133],\n",
       "         [208, 189, 130],\n",
       "         [205, 187, 131]],\n",
       "\n",
       "        [[231, 205, 146],\n",
       "         [230, 206, 148],\n",
       "         [234, 211, 154],\n",
       "         ...,\n",
       "         [221, 197, 139],\n",
       "         [211, 188, 135],\n",
       "         [210, 186, 133]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 92,  81,  58],\n",
       "         [ 88,  80,  59],\n",
       "         [ 92,  82,  56],\n",
       "         ...,\n",
       "         [153, 146, 106],\n",
       "         [164, 157, 110],\n",
       "         [166, 155, 103]],\n",
       "\n",
       "        [[ 86,  75,  57],\n",
       "         [ 82,  74,  53],\n",
       "         [ 86,  76,  51],\n",
       "         ...,\n",
       "         [133, 125,  82],\n",
       "         [152, 145,  95],\n",
       "         [138, 129,  79]],\n",
       "\n",
       "        [[ 68,  60,  49],\n",
       "         [ 64,  59,  47],\n",
       "         [ 60,  54,  41],\n",
       "         ...,\n",
       "         [ 91,  86,  50],\n",
       "         [100,  96,  57],\n",
       "         [ 86,  82,  45]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       "\n",
       "        [[255, 255, 255],\n",
       "         [253, 253, 253],\n",
       "         [254, 254, 254],\n",
       "         ...,\n",
       "         [254, 254, 254],\n",
       "         [252, 254, 253],\n",
       "         [254, 255, 255]],\n",
       "\n",
       "        [[255, 255, 255],\n",
       "         [254, 254, 254],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [254, 255, 255],\n",
       "         [253, 254, 254],\n",
       "         [254, 255, 255]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 77,  73,  68],\n",
       "         [ 81,  77,  70],\n",
       "         [ 79,  76,  67],\n",
       "         ...,\n",
       "         [ 78,  80,  73],\n",
       "         [ 76,  75,  69],\n",
       "         [ 78,  73,  66]],\n",
       "\n",
       "        [[ 64,  60,  54],\n",
       "         [ 63,  60,  52],\n",
       "         [ 72,  70,  60],\n",
       "         ...,\n",
       "         [ 68,  71,  64],\n",
       "         [ 74,  73,  69],\n",
       "         [ 78,  69,  67]],\n",
       "\n",
       "        [[ 59,  56,  50],\n",
       "         [ 66,  63,  54],\n",
       "         [ 75,  72,  62],\n",
       "         ...,\n",
       "         [ 62,  64,  56],\n",
       "         [ 66,  64,  59],\n",
       "         [ 71,  64,  61]]],\n",
       "\n",
       "\n",
       "       [[[187, 205, 240],\n",
       "         [197, 209, 240],\n",
       "         [200, 209, 236],\n",
       "         ...,\n",
       "         [244, 245, 249],\n",
       "         [242, 243, 248],\n",
       "         [243, 243, 249]],\n",
       "\n",
       "        [[148, 174, 219],\n",
       "         [169, 187, 227],\n",
       "         [184, 196, 231],\n",
       "         ...,\n",
       "         [239, 239, 244],\n",
       "         [245, 246, 251],\n",
       "         [248, 248, 253]],\n",
       "\n",
       "        [[155, 182, 229],\n",
       "         [162, 185, 228],\n",
       "         [177, 196, 235],\n",
       "         ...,\n",
       "         [239, 239, 248],\n",
       "         [241, 241, 249],\n",
       "         [240, 241, 247]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 54,  67,  77],\n",
       "         [ 57,  70,  79],\n",
       "         [ 56,  69,  78],\n",
       "         ...,\n",
       "         [ 92, 113, 116],\n",
       "         [ 98, 119, 125],\n",
       "         [ 96, 116, 124]],\n",
       "\n",
       "        [[ 42,  55,  63],\n",
       "         [ 41,  54,  62],\n",
       "         [ 40,  53,  61],\n",
       "         ...,\n",
       "         [ 77,  98, 100],\n",
       "         [ 94, 115, 119],\n",
       "         [ 90, 111, 117]],\n",
       "\n",
       "        [[ 32,  46,  52],\n",
       "         [ 32,  45,  51],\n",
       "         [ 35,  48,  54],\n",
       "         ...,\n",
       "         [ 74,  95,  95],\n",
       "         [ 80, 101, 103],\n",
       "         [ 80, 101, 106]]],\n",
       "\n",
       "\n",
       "       [[[107,  97,  87],\n",
       "         [100,  86,  81],\n",
       "         [109,  92,  90],\n",
       "         ...,\n",
       "         [148, 129, 123],\n",
       "         [151, 132, 126],\n",
       "         [145, 124, 120]],\n",
       "\n",
       "        [[109,  97,  90],\n",
       "         [ 99,  83,  83],\n",
       "         [110,  92,  94],\n",
       "         ...,\n",
       "         [122, 103,  96],\n",
       "         [127, 108, 101],\n",
       "         [131, 111, 104]],\n",
       "\n",
       "        [[109,  96,  85],\n",
       "         [114,  98,  94],\n",
       "         [130, 112, 111],\n",
       "         ...,\n",
       "         [115,  96,  88],\n",
       "         [120, 101,  94],\n",
       "         [127, 107,  96]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[143, 121, 109],\n",
       "         [149, 127, 117],\n",
       "         [154, 131, 124],\n",
       "         ...,\n",
       "         [143, 125, 118],\n",
       "         [139, 123, 116],\n",
       "         [141, 125, 119]],\n",
       "\n",
       "        [[142, 122, 111],\n",
       "         [143, 124, 115],\n",
       "         [149, 129, 122],\n",
       "         ...,\n",
       "         [148, 131, 125],\n",
       "         [146, 130, 125],\n",
       "         [142, 127, 123]],\n",
       "\n",
       "        [[143, 125, 115],\n",
       "         [143, 125, 116],\n",
       "         [145, 127, 120],\n",
       "         ...,\n",
       "         [152, 136, 131],\n",
       "         [145, 130, 125],\n",
       "         [141, 127, 122]]]], dtype=uint8)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9eab2fb6-4133-45cc-94f6-326fe1713187",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train0 = X_train0.astype('float64') / 255.0\n",
    "X_test0 = X_test0.astype('float64') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "5fc18066-9a00-45ff-ba60-b0a52168e9c5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.4117647 , 0.4509804 , 0.64705884],\n",
       "         [0.34117648, 0.3764706 , 0.6       ],\n",
       "         [0.44705883, 0.4862745 , 0.69803923],\n",
       "         ...,\n",
       "         [0.16078432, 0.16078432, 0.27450982],\n",
       "         [0.12156863, 0.12156863, 0.23137255],\n",
       "         [0.12941177, 0.12941177, 0.23921569]],\n",
       "\n",
       "        [[0.4509804 , 0.49019608, 0.68235296],\n",
       "         [0.45490196, 0.49019608, 0.70980394],\n",
       "         [0.36862746, 0.40784314, 0.62352943],\n",
       "         ...,\n",
       "         [0.18431373, 0.1764706 , 0.30588236],\n",
       "         [0.1254902 , 0.12156863, 0.22745098],\n",
       "         [0.13333334, 0.13333334, 0.22745098]],\n",
       "\n",
       "        [[0.44313726, 0.4862745 , 0.6745098 ],\n",
       "         [0.5137255 , 0.54901963, 0.7764706 ],\n",
       "         [0.4       , 0.43529412, 0.6666667 ],\n",
       "         ...,\n",
       "         [0.18431373, 0.1764706 , 0.3254902 ],\n",
       "         [0.15294118, 0.15294118, 0.27058825],\n",
       "         [0.16078432, 0.16078432, 0.27058825]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.36862746, 0.36862746, 0.52156866],\n",
       "         [0.23921569, 0.23921569, 0.3647059 ],\n",
       "         [0.24313726, 0.22745098, 0.3529412 ],\n",
       "         ...,\n",
       "         [0.48235294, 0.50980395, 0.81960785],\n",
       "         [0.4627451 , 0.49411765, 0.8       ],\n",
       "         [0.44313726, 0.47843137, 0.78431374]],\n",
       "\n",
       "        [[0.34901962, 0.36862746, 0.5411765 ],\n",
       "         [0.2509804 , 0.27450982, 0.42352942],\n",
       "         [0.27450982, 0.27450982, 0.4117647 ],\n",
       "         ...,\n",
       "         [0.46666667, 0.5058824 , 0.81960785],\n",
       "         [0.45882353, 0.49411765, 0.8039216 ],\n",
       "         [0.4509804 , 0.48235294, 0.79607844]],\n",
       "\n",
       "        [[0.33333334, 0.3647059 , 0.5568628 ],\n",
       "         [0.25490198, 0.2784314 , 0.43137255],\n",
       "         [0.31764707, 0.30980393, 0.44313726],\n",
       "         ...,\n",
       "         [0.46666667, 0.5058824 , 0.81960785],\n",
       "         [0.45882353, 0.49411765, 0.8117647 ],\n",
       "         [0.4509804 , 0.48235294, 0.8       ]]],\n",
       "\n",
       "\n",
       "       [[[0.68235296, 0.63529414, 0.5882353 ],\n",
       "         [0.7647059 , 0.7176471 , 0.6666667 ],\n",
       "         [0.84705883, 0.8       , 0.74509805],\n",
       "         ...,\n",
       "         [0.6392157 , 0.6117647 , 0.5647059 ],\n",
       "         [0.5176471 , 0.50980395, 0.49019608],\n",
       "         [0.40784314, 0.40784314, 0.44705883]],\n",
       "\n",
       "        [[0.7764706 , 0.7294118 , 0.6666667 ],\n",
       "         [0.80784315, 0.7607843 , 0.70980394],\n",
       "         [0.83137256, 0.78431374, 0.7411765 ],\n",
       "         ...,\n",
       "         [0.46666667, 0.44313726, 0.42745098],\n",
       "         [0.28235295, 0.28235295, 0.29803923],\n",
       "         [0.26666668, 0.2784314 , 0.34509805]],\n",
       "\n",
       "        [[0.62352943, 0.57254905, 0.5372549 ],\n",
       "         [0.65882355, 0.6117647 , 0.56078434],\n",
       "         [0.75686276, 0.70980394, 0.64705884],\n",
       "         ...,\n",
       "         [0.22745098, 0.20784314, 0.23137255],\n",
       "         [0.1882353 , 0.19215687, 0.24705882],\n",
       "         [0.23921569, 0.25882354, 0.34901962]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.50980395, 0.49411765, 0.49019608],\n",
       "         [0.49411765, 0.47843137, 0.46666667],\n",
       "         [0.49019608, 0.4627451 , 0.4509804 ],\n",
       "         ...,\n",
       "         [0.42745098, 0.50980395, 0.5882353 ],\n",
       "         [0.32156864, 0.42352942, 0.5294118 ],\n",
       "         [0.32156864, 0.43529412, 0.54901963]],\n",
       "\n",
       "        [[0.45882353, 0.4627451 , 0.45882353],\n",
       "         [0.45882353, 0.4627451 , 0.4627451 ],\n",
       "         [0.44705883, 0.4509804 , 0.45882353],\n",
       "         ...,\n",
       "         [0.3137255 , 0.4117647 , 0.5058824 ],\n",
       "         [0.3019608 , 0.40784314, 0.52156866],\n",
       "         [0.3254902 , 0.43137255, 0.54509807]],\n",
       "\n",
       "        [[0.47058824, 0.5019608 , 0.49411765],\n",
       "         [0.45490196, 0.49019608, 0.49019608],\n",
       "         [0.40392157, 0.44705883, 0.45490196],\n",
       "         ...,\n",
       "         [0.43137255, 0.53333336, 0.63529414],\n",
       "         [0.39215687, 0.49803922, 0.6156863 ],\n",
       "         [0.3254902 , 0.43529412, 0.5529412 ]]],\n",
       "\n",
       "\n",
       "       [[[0.94509804, 0.84313726, 0.61960787],\n",
       "         [0.9372549 , 0.84705883, 0.63529414],\n",
       "         [0.9529412 , 0.8627451 , 0.65882355],\n",
       "         ...,\n",
       "         [0.827451  , 0.75686276, 0.53333336],\n",
       "         [0.7921569 , 0.7254902 , 0.49411765],\n",
       "         [0.7764706 , 0.72156864, 0.5137255 ]],\n",
       "\n",
       "        [[0.94509804, 0.8392157 , 0.6156863 ],\n",
       "         [0.9411765 , 0.8509804 , 0.627451  ],\n",
       "         [0.9490196 , 0.8627451 , 0.63529414],\n",
       "         ...,\n",
       "         [0.84705883, 0.76862746, 0.52156866],\n",
       "         [0.8156863 , 0.7411765 , 0.50980395],\n",
       "         [0.8039216 , 0.73333335, 0.5137255 ]],\n",
       "\n",
       "        [[0.90588236, 0.8039216 , 0.57254905],\n",
       "         [0.9019608 , 0.80784315, 0.5803922 ],\n",
       "         [0.91764706, 0.827451  , 0.6039216 ],\n",
       "         ...,\n",
       "         [0.8666667 , 0.77254903, 0.54509807],\n",
       "         [0.827451  , 0.7372549 , 0.5294118 ],\n",
       "         [0.8235294 , 0.7294118 , 0.52156866]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.36078432, 0.31764707, 0.22745098],\n",
       "         [0.34509805, 0.3137255 , 0.23137255],\n",
       "         [0.36078432, 0.32156864, 0.21960784],\n",
       "         ...,\n",
       "         [0.6       , 0.57254905, 0.41568628],\n",
       "         [0.6431373 , 0.6156863 , 0.43137255],\n",
       "         [0.6509804 , 0.60784316, 0.40392157]],\n",
       "\n",
       "        [[0.3372549 , 0.29411766, 0.22352941],\n",
       "         [0.32156864, 0.2901961 , 0.20784314],\n",
       "         [0.3372549 , 0.29803923, 0.2       ],\n",
       "         ...,\n",
       "         [0.52156866, 0.49019608, 0.32156864],\n",
       "         [0.59607846, 0.5686275 , 0.37254903],\n",
       "         [0.5411765 , 0.5058824 , 0.30980393]],\n",
       "\n",
       "        [[0.26666668, 0.23529412, 0.19215687],\n",
       "         [0.2509804 , 0.23137255, 0.18431373],\n",
       "         [0.23529412, 0.21176471, 0.16078432],\n",
       "         ...,\n",
       "         [0.35686275, 0.3372549 , 0.19607843],\n",
       "         [0.39215687, 0.3764706 , 0.22352941],\n",
       "         [0.3372549 , 0.32156864, 0.1764706 ]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [0.99215686, 0.99215686, 0.99215686],\n",
       "         [0.99607843, 0.99607843, 0.99607843],\n",
       "         ...,\n",
       "         [0.99607843, 0.99607843, 0.99607843],\n",
       "         [0.9882353 , 0.99607843, 0.99215686],\n",
       "         [0.99607843, 1.        , 1.        ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [0.99607843, 0.99607843, 0.99607843],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [0.99607843, 1.        , 1.        ],\n",
       "         [0.99215686, 0.99607843, 0.99607843],\n",
       "         [0.99607843, 1.        , 1.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.3019608 , 0.28627452, 0.26666668],\n",
       "         [0.31764707, 0.3019608 , 0.27450982],\n",
       "         [0.30980393, 0.29803923, 0.2627451 ],\n",
       "         ...,\n",
       "         [0.30588236, 0.3137255 , 0.28627452],\n",
       "         [0.29803923, 0.29411766, 0.27058825],\n",
       "         [0.30588236, 0.28627452, 0.25882354]],\n",
       "\n",
       "        [[0.2509804 , 0.23529412, 0.21176471],\n",
       "         [0.24705882, 0.23529412, 0.20392157],\n",
       "         [0.28235295, 0.27450982, 0.23529412],\n",
       "         ...,\n",
       "         [0.26666668, 0.2784314 , 0.2509804 ],\n",
       "         [0.2901961 , 0.28627452, 0.27058825],\n",
       "         [0.30588236, 0.27058825, 0.2627451 ]],\n",
       "\n",
       "        [[0.23137255, 0.21960784, 0.19607843],\n",
       "         [0.25882354, 0.24705882, 0.21176471],\n",
       "         [0.29411766, 0.28235295, 0.24313726],\n",
       "         ...,\n",
       "         [0.24313726, 0.2509804 , 0.21960784],\n",
       "         [0.25882354, 0.2509804 , 0.23137255],\n",
       "         [0.2784314 , 0.2509804 , 0.23921569]]],\n",
       "\n",
       "\n",
       "       [[[0.73333335, 0.8039216 , 0.9411765 ],\n",
       "         [0.77254903, 0.81960785, 0.9411765 ],\n",
       "         [0.78431374, 0.81960785, 0.9254902 ],\n",
       "         ...,\n",
       "         [0.95686275, 0.9607843 , 0.9764706 ],\n",
       "         [0.9490196 , 0.9529412 , 0.972549  ],\n",
       "         [0.9529412 , 0.9529412 , 0.9764706 ]],\n",
       "\n",
       "        [[0.5803922 , 0.68235296, 0.85882354],\n",
       "         [0.6627451 , 0.73333335, 0.8901961 ],\n",
       "         [0.72156864, 0.76862746, 0.90588236],\n",
       "         ...,\n",
       "         [0.9372549 , 0.9372549 , 0.95686275],\n",
       "         [0.9607843 , 0.9647059 , 0.9843137 ],\n",
       "         [0.972549  , 0.972549  , 0.99215686]],\n",
       "\n",
       "        [[0.60784316, 0.7137255 , 0.8980392 ],\n",
       "         [0.63529414, 0.7254902 , 0.89411765],\n",
       "         [0.69411767, 0.76862746, 0.92156863],\n",
       "         ...,\n",
       "         [0.9372549 , 0.9372549 , 0.972549  ],\n",
       "         [0.94509804, 0.94509804, 0.9764706 ],\n",
       "         [0.9411765 , 0.94509804, 0.96862745]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.21176471, 0.2627451 , 0.3019608 ],\n",
       "         [0.22352941, 0.27450982, 0.30980393],\n",
       "         [0.21960784, 0.27058825, 0.30588236],\n",
       "         ...,\n",
       "         [0.36078432, 0.44313726, 0.45490196],\n",
       "         [0.38431373, 0.46666667, 0.49019608],\n",
       "         [0.3764706 , 0.45490196, 0.4862745 ]],\n",
       "\n",
       "        [[0.16470589, 0.21568628, 0.24705882],\n",
       "         [0.16078432, 0.21176471, 0.24313726],\n",
       "         [0.15686275, 0.20784314, 0.23921569],\n",
       "         ...,\n",
       "         [0.3019608 , 0.38431373, 0.39215687],\n",
       "         [0.36862746, 0.4509804 , 0.46666667],\n",
       "         [0.3529412 , 0.43529412, 0.45882353]],\n",
       "\n",
       "        [[0.1254902 , 0.18039216, 0.20392157],\n",
       "         [0.1254902 , 0.1764706 , 0.2       ],\n",
       "         [0.13725491, 0.1882353 , 0.21176471],\n",
       "         ...,\n",
       "         [0.2901961 , 0.37254903, 0.37254903],\n",
       "         [0.3137255 , 0.39607844, 0.40392157],\n",
       "         [0.3137255 , 0.39607844, 0.41568628]]],\n",
       "\n",
       "\n",
       "       [[[0.41960785, 0.38039216, 0.34117648],\n",
       "         [0.39215687, 0.3372549 , 0.31764707],\n",
       "         [0.42745098, 0.36078432, 0.3529412 ],\n",
       "         ...,\n",
       "         [0.5803922 , 0.5058824 , 0.48235294],\n",
       "         [0.5921569 , 0.5176471 , 0.49411765],\n",
       "         [0.5686275 , 0.4862745 , 0.47058824]],\n",
       "\n",
       "        [[0.42745098, 0.38039216, 0.3529412 ],\n",
       "         [0.3882353 , 0.3254902 , 0.3254902 ],\n",
       "         [0.43137255, 0.36078432, 0.36862746],\n",
       "         ...,\n",
       "         [0.47843137, 0.40392157, 0.3764706 ],\n",
       "         [0.49803922, 0.42352942, 0.39607844],\n",
       "         [0.5137255 , 0.43529412, 0.40784314]],\n",
       "\n",
       "        [[0.42745098, 0.3764706 , 0.33333334],\n",
       "         [0.44705883, 0.38431373, 0.36862746],\n",
       "         [0.50980395, 0.4392157 , 0.43529412],\n",
       "         ...,\n",
       "         [0.4509804 , 0.3764706 , 0.34509805],\n",
       "         [0.47058824, 0.39607844, 0.36862746],\n",
       "         [0.49803922, 0.41960785, 0.3764706 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.56078434, 0.4745098 , 0.42745098],\n",
       "         [0.58431375, 0.49803922, 0.45882353],\n",
       "         [0.6039216 , 0.5137255 , 0.4862745 ],\n",
       "         ...,\n",
       "         [0.56078434, 0.49019608, 0.4627451 ],\n",
       "         [0.54509807, 0.48235294, 0.45490196],\n",
       "         [0.5529412 , 0.49019608, 0.46666667]],\n",
       "\n",
       "        [[0.5568628 , 0.47843137, 0.43529412],\n",
       "         [0.56078434, 0.4862745 , 0.4509804 ],\n",
       "         [0.58431375, 0.5058824 , 0.47843137],\n",
       "         ...,\n",
       "         [0.5803922 , 0.5137255 , 0.49019608],\n",
       "         [0.57254905, 0.50980395, 0.49019608],\n",
       "         [0.5568628 , 0.49803922, 0.48235294]],\n",
       "\n",
       "        [[0.56078434, 0.49019608, 0.4509804 ],\n",
       "         [0.56078434, 0.49019608, 0.45490196],\n",
       "         [0.5686275 , 0.49803922, 0.47058824],\n",
       "         ...,\n",
       "         [0.59607846, 0.53333336, 0.5137255 ],\n",
       "         [0.5686275 , 0.50980395, 0.49019608],\n",
       "         [0.5529412 , 0.49803922, 0.47843137]]]], dtype=float32)"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a9e89c-f99d-48e7-9654-df739c3afb01",
   "metadata": {
    "tags": []
   },
   "source": [
    "## changing form of output from sparse Categorical Cross-Entropy to categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "3eb576e4-3b75-4789-841c-2d6de90bfc95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4],\n",
       "       [4],\n",
       "       [4],\n",
       "       ...,\n",
       "       [8],\n",
       "       [8],\n",
       "       [4]], dtype=uint8)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1c379cf0-02f0-4059-a749-c93e737e9e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_hot = to_categorical(y_train0)\n",
    "y_test_hot = to_categorical(y_test0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "ccc16830-0e51-4c8e-9293-88f89aeb029f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f788da3-bec8-4ec8-a930-d8780d44be09",
   "metadata": {},
   "source": [
    "# Define Model with 4 hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "015e73c5-bc37-4de4-b36b-bd25aedbc8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann_model():\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(Flatten(input_shape=[32, 32, 3]))\n",
    "    model.add(Dense(units=250, activation='relu'))\n",
    "    model.add(Dense(units=150, activation='relu'))\n",
    "    model.add(Dense(units=100, activation='relu'))\n",
    "    model.add(Dense(units=50, activation='relu'))\n",
    "    model.add(Dense(units=10, activation='softmax'))\n",
    "    model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "073668d9-bd28-4177-982d-af840f95336d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.reshaping.flatten.Flatten at 0x7fab3f9abeb0>,\n",
       " <keras.layers.core.dense.Dense at 0x7fab4052b100>,\n",
       " <keras.layers.core.dense.Dense at 0x7fab40529270>,\n",
       " <keras.layers.core.dense.Dense at 0x7fab3f9bc220>,\n",
       " <keras.layers.core.dense.Dense at 0x7fab3f957640>,\n",
       " <keras.layers.core.dense.Dense at 0x7fab40528430>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ann_model()\n",
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c0b5c776-68eb-4124-bea2-1e367fbad308",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1 , X_val , y_train1 , y_val = train_test_split(X_train0,y_train_hot ,test_size = 0.2 ,random_state = 42 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "37e64e52-266d-464e-98cb-978829ca73e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1275/1275 [==============================] - 8s 6ms/step - loss: 1.9512 - accuracy: 0.2936 - val_loss: 1.8774 - val_accuracy: 0.3274\n",
      "Epoch 2/30\n",
      "1275/1275 [==============================] - 6s 5ms/step - loss: 1.7616 - accuracy: 0.3706 - val_loss: 1.6689 - val_accuracy: 0.4096\n",
      "Epoch 3/30\n",
      "1275/1275 [==============================] - 6s 5ms/step - loss: 1.6695 - accuracy: 0.4070 - val_loss: 1.6517 - val_accuracy: 0.4093\n",
      "Epoch 4/30\n",
      "1275/1275 [==============================] - 6s 5ms/step - loss: 1.6088 - accuracy: 0.4271 - val_loss: 1.5578 - val_accuracy: 0.4502\n",
      "Epoch 5/30\n",
      "1275/1275 [==============================] - 6s 5ms/step - loss: 1.5572 - accuracy: 0.4435 - val_loss: 1.5587 - val_accuracy: 0.4396\n",
      "Epoch 6/30\n",
      "1275/1275 [==============================] - 6s 5ms/step - loss: 1.5174 - accuracy: 0.4594 - val_loss: 1.5225 - val_accuracy: 0.4595\n",
      "Epoch 7/30\n",
      "1275/1275 [==============================] - 7s 5ms/step - loss: 1.4823 - accuracy: 0.4691 - val_loss: 1.4770 - val_accuracy: 0.4763\n",
      "Epoch 8/30\n",
      "1275/1275 [==============================] - 7s 5ms/step - loss: 1.4556 - accuracy: 0.4785 - val_loss: 1.4450 - val_accuracy: 0.4895\n",
      "Epoch 9/30\n",
      "1275/1275 [==============================] - 7s 5ms/step - loss: 1.4283 - accuracy: 0.4881 - val_loss: 1.4408 - val_accuracy: 0.4918\n",
      "Epoch 10/30\n",
      "1275/1275 [==============================] - 6s 5ms/step - loss: 1.4029 - accuracy: 0.4990 - val_loss: 1.4120 - val_accuracy: 0.4999\n",
      "Epoch 11/30\n",
      "1275/1275 [==============================] - 7s 5ms/step - loss: 1.3771 - accuracy: 0.5093 - val_loss: 1.3910 - val_accuracy: 0.5065\n",
      "Epoch 12/30\n",
      "1275/1275 [==============================] - 6s 5ms/step - loss: 1.3588 - accuracy: 0.5136 - val_loss: 1.4237 - val_accuracy: 0.5025\n",
      "Epoch 13/30\n",
      "1275/1275 [==============================] - 6s 5ms/step - loss: 1.3350 - accuracy: 0.5234 - val_loss: 1.4780 - val_accuracy: 0.4766\n",
      "Epoch 14/30\n",
      "1275/1275 [==============================] - 7s 5ms/step - loss: 1.3123 - accuracy: 0.5320 - val_loss: 1.4162 - val_accuracy: 0.5011\n",
      "Epoch 15/30\n",
      "1275/1275 [==============================] - 6s 5ms/step - loss: 1.2961 - accuracy: 0.5338 - val_loss: 1.4008 - val_accuracy: 0.5086\n",
      "Epoch 16/30\n",
      "1275/1275 [==============================] - 6s 5ms/step - loss: 1.2773 - accuracy: 0.5438 - val_loss: 1.3958 - val_accuracy: 0.5028\n",
      "Epoch 17/30\n",
      "1275/1275 [==============================] - 6s 5ms/step - loss: 1.2553 - accuracy: 0.5497 - val_loss: 1.3642 - val_accuracy: 0.5218\n",
      "Epoch 18/30\n",
      "1275/1275 [==============================] - 7s 5ms/step - loss: 1.2420 - accuracy: 0.5567 - val_loss: 1.3776 - val_accuracy: 0.5154\n",
      "Epoch 19/30\n",
      "1275/1275 [==============================] - 7s 5ms/step - loss: 1.2196 - accuracy: 0.5623 - val_loss: 1.3750 - val_accuracy: 0.5207\n",
      "Epoch 20/30\n",
      "1275/1275 [==============================] - 7s 5ms/step - loss: 1.2006 - accuracy: 0.5698 - val_loss: 1.3434 - val_accuracy: 0.5265\n",
      "Epoch 21/30\n",
      "1275/1275 [==============================] - 7s 5ms/step - loss: 1.1866 - accuracy: 0.5743 - val_loss: 1.3625 - val_accuracy: 0.5269\n",
      "Epoch 22/30\n",
      "1275/1275 [==============================] - 7s 5ms/step - loss: 1.1655 - accuracy: 0.5802 - val_loss: 1.3572 - val_accuracy: 0.5275\n",
      "Epoch 23/30\n",
      "1275/1275 [==============================] - 7s 5ms/step - loss: 1.1544 - accuracy: 0.5843 - val_loss: 1.3703 - val_accuracy: 0.5297\n",
      "Epoch 24/30\n",
      "1275/1275 [==============================] - 6s 5ms/step - loss: 1.1384 - accuracy: 0.5909 - val_loss: 1.3905 - val_accuracy: 0.5174\n",
      "Epoch 25/30\n",
      "1275/1275 [==============================] - 7s 5ms/step - loss: 1.1239 - accuracy: 0.5994 - val_loss: 1.3868 - val_accuracy: 0.5201\n",
      "Epoch 26/30\n",
      "1275/1275 [==============================] - 7s 5ms/step - loss: 1.1057 - accuracy: 0.6016 - val_loss: 1.3708 - val_accuracy: 0.5291\n",
      "Epoch 27/30\n",
      "1275/1275 [==============================] - 7s 5ms/step - loss: 1.0901 - accuracy: 0.6097 - val_loss: 1.3619 - val_accuracy: 0.5276\n",
      "Epoch 28/30\n",
      "1275/1275 [==============================] - 7s 5ms/step - loss: 1.0747 - accuracy: 0.6152 - val_loss: 1.3858 - val_accuracy: 0.5298\n",
      "Epoch 29/30\n",
      "1275/1275 [==============================] - 7s 5ms/step - loss: 1.0549 - accuracy: 0.6220 - val_loss: 1.3952 - val_accuracy: 0.5292\n",
      "Epoch 30/30\n",
      "1275/1275 [==============================] - 6s 5ms/step - loss: 1.0421 - accuracy: 0.6268 - val_loss: 1.3724 - val_accuracy: 0.5254\n"
     ]
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "history = model.fit(X_train1, y_train1, epochs=30, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "208d266e-4d6d-4d62-a80b-5f9c335312f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1594/1594 [==============================] - 2s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict the outputs for the test dataset\n",
    "y_pred = np.argmax(model.predict(X_train0), axis=1)\n",
    "y_pred = to_categorical(y_pred)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bc465c7c-6ae7-4b39-bbb3-117d24367af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c313fa26-adcb-4cba-b872-c112b392f437",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "619add6d-b17d-42c3-8342-ca0a8f64e365",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using hp parameter, which used the hyperparameters for tuning the model.\n",
    "def model_builder(hp):\n",
    "    #Creating a sequential model\n",
    "    model = keras.models.Sequential()\n",
    "    #adding a flatten layer to the model\n",
    "    model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "\n",
    "    # Creating a  loop =to tune the number of hidden layers in the model\n",
    "    #the number of dense layers, ranging from 1 to 5\n",
    "    for i in range(hp.Int('num_layers', 1, 5)):\n",
    "    \n",
    "        #  hp_units is defined to tune the number of units in each dense layer. It ranges from 50 to 500 with a step of 50.\n",
    "        hp_units = hp.Int('units_'+str(i), min_value=50, max_value=500, step=50)\n",
    "        # Setting units to the value of hp_units and the activation function is set to relu\n",
    "        model.add(keras.layers.Dense(units=hp_units, activation='relu'))\n",
    "    \n",
    "    \n",
    "  # Adds a dense output layer with 10 units\n",
    "    model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "  # hp_learning_rate is defined to tune the learning rate for the optimizer\n",
    "  # creating a hyperparameter for the learning rate, with the  values of 0.01, 0.001, and 0.0001\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    #Compiling the model with the sgd optimizer and the learning rate according to hp_learning_rate\n",
    "    model.compile(optimizer=keras.optimizers.SGD(learning_rate=hp_learning_rate),\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9fe346b4-b5fe-4709-94eb-727351641e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = keras_tuner.RandomSearch(\n",
    "# definning the model architecture\n",
    "model_builder,\n",
    "#The metric to consider as optimization during the hyperparameter search\n",
    "objective='val_accuracy',\n",
    "# The maximum number of hyperparameter tuning to try during the search\n",
    "max_trials=20,\n",
    "# A parameter to overwrite the results of previous tries, it will overwrite any existing results\n",
    "overwrite=True,\n",
    "# The directory where the search results will be saved\n",
    "directory=\"my_dir\",\n",
    "# The name of the project\n",
    "project_name=\"Tuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "35ef8566-80a2-41eb-88b8-1b40f5952471",
   "metadata": {},
   "outputs": [],
   "source": [
    "#callback is used to do early stopping during the training  , monitor: The metric to monitor for early stopping and patience: if the monitored metric does not improve , training will be stopped early.\n",
    "stop_early = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1df72cfb-863f-494c-a5e4-e8635073057e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20 Complete [00h 05m 12s]\n",
      "val_accuracy: 0.3466666638851166\n",
      "\n",
      "Best val_accuracy So Far: 0.5065686106681824\n",
      "Total elapsed time: 01h 00m 52s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "# The epochs parameter specifies the number of training epochs to be used during the search\n",
    "tuner.search(X_train0, y_train_hot, epochs=20, validation_split=0.2, callbacks=[stop_early])\n",
    "\n",
    "# Get the best hyperparameters found during the search and The num_trials=1 get only the best set of hyperparameters and The [0] indexing is used to extract the first set of best hyperparameters from the list of results\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "05432e5b-ff5a-4b4a-941b-8302f96c1dfa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 3072)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 300)               921900    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 150)               45150     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                1510      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 968,560\n",
      "Trainable params: 968,560\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# return the top 2 best models \n",
    "models = tuner.get_best_models(num_models=2)\n",
    "best_model = models[0]\n",
    "# Build the model.\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "88318ad6-2978-4f00-b3d9-faa9c8e2d9bd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in my_dir/Tuning\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 17 summary\n",
      "Hyperparameters:\n",
      "num_layers: 2\n",
      "units_0: 300\n",
      "learning_rate: 0.01\n",
      "units_1: 150\n",
      "units_2: 100\n",
      "units_3: 150\n",
      "units_4: 250\n",
      "Score: 0.5065686106681824\n",
      "\n",
      "Trial 01 summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 150\n",
      "learning_rate: 0.01\n",
      "Score: 0.464607834815979\n",
      "\n",
      "Trial 06 summary\n",
      "Hyperparameters:\n",
      "num_layers: 4\n",
      "units_0: 500\n",
      "learning_rate: 0.001\n",
      "units_1: 400\n",
      "units_2: 350\n",
      "units_3: 400\n",
      "units_4: 50\n",
      "Score: 0.44774508476257324\n",
      "\n",
      "Trial 10 summary\n",
      "Hyperparameters:\n",
      "num_layers: 3\n",
      "units_0: 450\n",
      "learning_rate: 0.001\n",
      "units_1: 250\n",
      "units_2: 250\n",
      "units_3: 350\n",
      "units_4: 200\n",
      "Score: 0.44205883145332336\n",
      "\n",
      "Trial 02 summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 150\n",
      "learning_rate: 0.001\n",
      "Score: 0.43156862258911133\n",
      "\n",
      "Trial 13 summary\n",
      "Hyperparameters:\n",
      "num_layers: 4\n",
      "units_0: 150\n",
      "learning_rate: 0.001\n",
      "units_1: 150\n",
      "units_2: 200\n",
      "units_3: 100\n",
      "units_4: 350\n",
      "Score: 0.4300000071525574\n",
      "\n",
      "Trial 09 summary\n",
      "Hyperparameters:\n",
      "num_layers: 2\n",
      "units_0: 400\n",
      "learning_rate: 0.001\n",
      "units_1: 50\n",
      "units_2: 400\n",
      "units_3: 350\n",
      "units_4: 150\n",
      "Score: 0.42901960015296936\n",
      "\n",
      "Trial 18 summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 200\n",
      "learning_rate: 0.001\n",
      "units_1: 100\n",
      "units_2: 100\n",
      "units_3: 300\n",
      "units_4: 50\n",
      "Score: 0.4269607961177826\n",
      "\n",
      "Trial 03 summary\n",
      "Hyperparameters:\n",
      "num_layers: 5\n",
      "units_0: 250\n",
      "learning_rate: 0.001\n",
      "units_1: 50\n",
      "units_2: 50\n",
      "units_3: 50\n",
      "units_4: 50\n",
      "Score: 0.42009803652763367\n",
      "\n",
      "Trial 08 summary\n",
      "Hyperparameters:\n",
      "num_layers: 4\n",
      "units_0: 100\n",
      "learning_rate: 0.001\n",
      "units_1: 350\n",
      "units_2: 250\n",
      "units_3: 500\n",
      "units_4: 200\n",
      "Score: 0.4162745177745819\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fe5f9f-4096-4c59-bb80-9da08d1c8fbd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8d39c30a-baca-4f75-9c73-6a001204ebbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1594/1594 [==============================] - 2s 1ms/step\n",
      "319/319 [==============================] - 0s 1ms/step\n",
      "282/282 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train</td>\n",
       "      <td>0.621961</td>\n",
       "      <td>0.624628</td>\n",
       "      <td>0.789768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Validation</td>\n",
       "      <td>0.525392</td>\n",
       "      <td>0.525880</td>\n",
       "      <td>0.735098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Test</td>\n",
       "      <td>0.507000</td>\n",
       "      <td>0.510523</td>\n",
       "      <td>0.727194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Dataset  Accuracy  F1-Score   ROC AUC\n",
       "0       Train  0.621961  0.624628  0.789768\n",
       "1  Validation  0.525392  0.525880  0.735098\n",
       "2        Test  0.507000  0.510523  0.727194"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions on train, validation, and test data\n",
    "train_pred = np.argmax(model.predict(X_train0), axis=1)\n",
    "val_pred = np.argmax(model.predict(X_val), axis=1)\n",
    "test_pred = np.argmax(model.predict(X_test0), axis=1)\n",
    "# Round predictions for binary classification\n",
    "train_pred = to_categorical(train_pred)\n",
    "val_pred = to_categorical(val_pred)\n",
    "test_pred = to_categorical(test_pred)\n",
    "\n",
    "# Compute accuracy, f1-score, and roc_auc for train, validation, and test datasets\n",
    "train_acc = accuracy_score(y_train_hot, train_pred)\n",
    "train_f1score = f1_score(y_train_hot, train_pred, average='macro')\n",
    "train_rocauc = roc_auc_score(y_train_hot, train_pred, average='macro')\n",
    "\n",
    "val_acc = accuracy_score(y_val, val_pred)\n",
    "val_f1score = f1_score(y_val, val_pred, average='macro')\n",
    "val_rocauc = roc_auc_score(y_val, val_pred, average='macro')\n",
    "\n",
    "test_acc = accuracy_score(y_test_hot, test_pred)\n",
    "test_f1score = f1_score(y_test_hot, test_pred, average='macro')\n",
    "test_rocauc = roc_auc_score(y_test_hot, test_pred, average='macro')\n",
    "# Create a table to report the metrics\n",
    "data = {\n",
    "    'Dataset': ['Train', 'Validation', 'Test'],\n",
    "    'Accuracy': [train_acc, val_acc, test_acc],\n",
    "    'F1-Score': [train_f1score, val_f1score, test_f1score],\n",
    "    'ROC AUC': [train_rocauc, val_rocauc, test_rocauc]\n",
    "     }\n",
    "\n",
    "metrics = pd.DataFrame(data)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e4a407-f4a8-4a77-8b12-76e263c64fd3",
   "metadata": {},
   "source": [
    "### In this level i can not define better model but i used all subjects that i have learnt ,i hope it could be accepted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be747a53-9118-4408-97f4-b4d37062f525",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Define Wide and deep model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "50b54788-2227-4b73-882f-936f8cd8e622",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wide_and_deep_model():\n",
    "    # Input layer\n",
    "    inputs = keras.Input(shape=(32, 32, 3)) \n",
    "    \n",
    "    # Flatten the input\n",
    "    flattened = keras.layers.Flatten()(inputs)\n",
    "    \n",
    "    # Wide component\n",
    "    widelayer = keras.layers.Dense(units=400, activation='relu')(flattened)\n",
    "    \n",
    "    # Deep component\n",
    "    deeplayer = keras.layers.Dense(units=300, activation='relu')(flattened)\n",
    "    deeplayer1 = keras.layers.Dense(units=150, activation='relu')(deeplayer)\n",
    "    deeplayer2 = keras.layers.Dense(units=50, activation='relu')(deeplayer1)\n",
    "    \n",
    "    # Concatenate wide and deep components\n",
    "    concatenated = keras.layers.concatenate([widelayer, deeplayer2])\n",
    "    \n",
    "    # Output layer\n",
    "    outputs = keras.layers.Dense(units=10, activation='softmax')(concatenated)\n",
    "    \n",
    "    # Create the model\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "ae796416-1645-4060-bc65-a3bae5bcbc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and compile the wide and deep model\n",
    "wide_deep_model = wide_and_deep_model()\n",
    "wide_deep_model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "5de565e7-eaa0-4aa6-ba62-83467b352536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1275/1275 [==============================] - 16s 12ms/step - loss: 1.8869 - accuracy: 0.3290 - val_loss: 1.7955 - val_accuracy: 0.3659\n",
      "Epoch 2/10\n",
      "1275/1275 [==============================] - 15s 12ms/step - loss: 1.7086 - accuracy: 0.3991 - val_loss: 1.6848 - val_accuracy: 0.3934\n",
      "Epoch 3/10\n",
      "1275/1275 [==============================] - 15s 12ms/step - loss: 1.6301 - accuracy: 0.4245 - val_loss: 1.6137 - val_accuracy: 0.4325\n",
      "Epoch 4/10\n",
      "1275/1275 [==============================] - 15s 12ms/step - loss: 1.5756 - accuracy: 0.4468 - val_loss: 1.5745 - val_accuracy: 0.4401\n",
      "Epoch 5/10\n",
      "1275/1275 [==============================] - 15s 12ms/step - loss: 1.5343 - accuracy: 0.4622 - val_loss: 1.5426 - val_accuracy: 0.4517\n",
      "Epoch 6/10\n",
      "1275/1275 [==============================] - 15s 12ms/step - loss: 1.4951 - accuracy: 0.4768 - val_loss: 1.5395 - val_accuracy: 0.4546\n",
      "Epoch 7/10\n",
      "1275/1275 [==============================] - 15s 12ms/step - loss: 1.4645 - accuracy: 0.4869 - val_loss: 1.5355 - val_accuracy: 0.4542\n",
      "Epoch 8/10\n",
      "1275/1275 [==============================] - 15s 12ms/step - loss: 1.4354 - accuracy: 0.4959 - val_loss: 1.5007 - val_accuracy: 0.4703\n",
      "Epoch 9/10\n",
      "1275/1275 [==============================] - 15s 12ms/step - loss: 1.4082 - accuracy: 0.5049 - val_loss: 1.4771 - val_accuracy: 0.4711\n",
      "Epoch 10/10\n",
      "1275/1275 [==============================] - 15s 12ms/step - loss: 1.3856 - accuracy: 0.5161 - val_loss: 1.4666 - val_accuracy: 0.4832\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7daf0296c0>"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the wide and deep model\n",
    "wide_deep_model.fit(X_train0, y_train_hot, epochs=10, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "43ccb84f-bff1-4f18-a6e0-5c001ad62c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " flatten_4 (Flatten)            (None, 3072)         0           ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_18 (Dense)               (None, 300)          921900      ['flatten_4[0][0]']              \n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, 150)          45150       ['dense_18[0][0]']               \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 400)          1229200     ['flatten_4[0][0]']              \n",
      "                                                                                                  \n",
      " dense_20 (Dense)               (None, 50)           7550        ['dense_19[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 450)          0           ['dense_17[0][0]',               \n",
      "                                                                  'dense_20[0][0]']               \n",
      "                                                                                                  \n",
      " dense_21 (Dense)               (None, 10)           4510        ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,208,310\n",
      "Trainable params: 2,208,310\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "wide_deep_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "59c3944b-1808-45f2-86d0-d55810ff3965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 1s 3ms/step - loss: 1.4728 - accuracy: 0.4778\n"
     ]
    }
   ],
   "source": [
    "wide_deep_accuracy = wide_deep_model.evaluate(X_test0, y_test_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "d181d7f7-cebe-4d71-8073-2fed4d569c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 0s 1ms/step - loss: 1.4776 - accuracy: 0.4790\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the deep model\n",
    "deep_accuracy = model.evaluate(X_test0, y_test_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "206f93b3-78b5-4ba8-be2e-4ad9d8099b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wide and Deep Model Accuracy: [1.4728420972824097, 0.47777777910232544]\n",
      "Deep Model Accuracy: [1.477599859237671, 0.4790000021457672]\n"
     ]
    }
   ],
   "source": [
    "# Compare the results\n",
    "print(\"Wide and Deep Model Accuracy:\", wide_deep_accuracy)\n",
    "print(\"Deep Model Accuracy:\", deep_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267c6b4f-c692-43e3-86df-988a7a001879",
   "metadata": {},
   "source": [
    "# Genetic Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38032bef-ab37-4e1c-a495-f3c032df3cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wide_and_deep_model():\n",
    "    # Input layer\n",
    "    inputs = keras.Input(shape=(32, 32, 3)) \n",
    "    \n",
    "    # Flatten the input\n",
    "    flattened = keras.layers.Flatten()(inputs)\n",
    "    \n",
    "    # Wide component\n",
    "    widelayer = keras.layers.Dense(units=400, activation='relu')(flattened)\n",
    "    \n",
    "    # Deep component\n",
    "    deeplayer = keras.layers.Dense(units=300, activation='relu')(flattened)\n",
    "    deeplayer1 = keras.layers.Dense(units=150, activation='relu')(deeplayer)\n",
    "    deeplayer2 = keras.layers.Dense(units=50, activation='relu')(deeplayer1)\n",
    "    \n",
    "    # Concatenate wide and deep components\n",
    "    concatenated = keras.layers.concatenate([widelayer, deeplayer2])\n",
    "    \n",
    "    # Output layer\n",
    "    outputs = keras.layers.Dense(units=10, activation='softmax')(concatenated)\n",
    "    \n",
    "    # Create the model\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dbfd526a-ac86-4ad2-8338-e7b87e0947de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and compile the wide and deep model\n",
    "wide_deep_model = wide_and_deep_model()\n",
    "wide_deep_model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0996b9ab-0a3f-414e-88ae-76f51aa7fa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KerasClassifier(model=wide_and_deep_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e37fed36-4998-492e-8fb0-9ea65c7af94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = GeneticSelectionCV(\n",
    "        clf,\n",
    "        cv=5,\n",
    "        verbose=1,\n",
    "        scoring=\"accuracy\",\n",
    "        max_features=5,\n",
    "        n_population=50,\n",
    "        crossover_proba=0.5,\n",
    "        mutation_proba=0.2,\n",
    "        n_generations=40,\n",
    "        crossover_independent_proba=0.5,\n",
    "        mutation_independent_proba=0.05,\n",
    "        tournament_size=3,\n",
    "        n_gen_no_change=10,\n",
    "        caching=True,\n",
    "        n_jobs=-1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85872d62-53fd-4ccf-b5b2-22cd2941831a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train0 = X_train0.reshape(-1, 32 * 32 * 3)\n",
    "X_test0 = X_test0.reshape(-1, 32 * 32 * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ebe205d6-2cf5-428e-ac00-59b2d13dc533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51000,)\n"
     ]
    }
   ],
   "source": [
    "# Reshape the array\n",
    "y_train_sh = y_train0.reshape(-1)  # Reshape to (n_sample,)\n",
    "y_test_sh = y_test0.reshape(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "09cbcc7f-df33-41cc-9b83-6bc29eee669f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting features with genetic algorithm.\n",
      "gen\tnevals\tavg                            \tstd                            \tmin                            \tmax                            \n",
      "0  \t50    \t[ 0.176315  3.22      0.00301 ]\t[ 0.025201  1.360735  0.001168]\t[ 0.119235  1.        0.000969]\t[ 0.226961  5.        0.005215]\n",
      "1  \t30    \t[-2799.856402    40.52      2800.002362]\t[ 4490.078413    64.39231   4489.987391]\t[-10000.            1.            0.001127]\t[     0.226961    168.        10000.      ]\n",
      "2  \t24    \t[-3599.869556    40.34      3600.00226 ]\t[ 4800.097833    62.517073  4799.998305]\t[-10000.            1.            0.001415]\t[     0.226961    175.        10000.      ]\n",
      "3  \t28    \t[-2999.851972    30.9       3000.002446]\t[ 4582.672602    60.808634  4582.574094]\t[-10000.            1.            0.001293]\t[     0.226961    242.        10000.      ]\n",
      "4  \t33    \t[-3999.870663    52.36      4000.002112]\t[ 4899.085089    69.481151  4898.977761]\t[-10000.            3.            0.001293]\t[     0.226961    172.        10000.      ]\n",
      "5  \t31    \t[-3199.848224    41.24      3200.00268 ]\t[ 4664.865633    66.376068  4664.759677]\t[-10000.            4.            0.001293]\t[     0.227824    221.        10000.      ]\n",
      "6  \t34    \t[-3199.846368    40.96      3200.002939]\t[ 4664.866906    69.756995  4664.7595  ]\t[-10000.            4.            0.002484]\t[     0.227824    279.        10000.      ]\n",
      "7  \t31    \t[-2599.832588    38.88      2600.003044]\t[ 4386.441673    63.853783  4386.340636]\t[-10000.            3.            0.002484]\t[     0.231588    171.        10000.      ]\n",
      "8  \t25    \t[-3199.845904    49.24      3200.002647]\t[ 4664.867225    71.211392  4664.7597  ]\t[-10000.            3.            0.002484]\t[     0.231588    178.        10000.      ]\n",
      "9  \t28    \t[-1999.819313    22.34      2000.002707]\t[ 4000.090344    47.20153   3999.998647]\t[-10000.            3.            0.002433]\t[     0.231588    165.        10000.      ]\n",
      "10 \t23    \t[-2199.821049    35.1       2200.002353]\t[ 4142.558073    60.273792  4142.461786]\t[-10000.            4.            0.002484]\t[     0.231588    165.        10000.      ]\n",
      "11 \t32    \t[-1599.80601     29.46      1600.002532]\t[ 3666.14522     56.117095  3666.059451]\t[-10000.            5.            0.002484]\t[     0.231588    165.        10000.      ]\n",
      "12 \t34    \t[-2399.823993    41.78      2400.00232 ]\t[ 4270.930208    65.620512  4270.829997]\t[-10000.            5.            0.003053]\t[     0.231588    173.        10000.      ]\n",
      "13 \t33    \t[-2399.823993    41.46      2400.00232 ]\t[ 4270.930208    65.210493  4270.829997]\t[-10000.            5.            0.003053]\t[     0.231588    177.        10000.      ]\n",
      "14 \t30    \t[-2199.819361    37.9       2200.002381]\t[ 4142.55897     62.26275   4142.461771]\t[-10000.            5.            0.003053]\t[     0.231588    190.        10000.      ]\n",
      "15 \t31    \t[-2199.819361    37.34      2200.002381]\t[ 4142.55897     61.291634  4142.461771]\t[-10000.            5.            0.003053]\t[     0.231588    177.        10000.      ]\n",
      "16 \t33    \t[-2399.823993    45.        2400.00232 ]\t[ 4270.930208    73.239607  4270.829997]\t[-10000.            5.            0.003053]\t[     0.231588    284.        10000.      ]\n",
      "17 \t35    \t[-1799.810098    32.64      1800.002503]\t[ 3841.963516    59.123518  3841.87337 ]\t[-10000.            5.            0.003053]\t[     0.231588    176.        10000.      ]\n"
     ]
    }
   ],
   "source": [
    "selector = selector.fit(X_train0, y_train_sh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1a2770fc-8001-4fc0-91e8-a692801507a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: [False False False ... False False False]\n"
     ]
    }
   ],
   "source": [
    "# Print the selected feature indices\n",
    "print(\"Selected Features:\", selector.support_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e055f818-a152-44e4-b8c7-45bc4b0314dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.22922222222222222\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model with selected features\n",
    "accuracy = selector.score(X_test0, y_test_sh)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
